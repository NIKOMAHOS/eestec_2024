{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrRLW8RCvOwP",
        "outputId": "cce9b34e-f7c7-48d6-c826-6397d569d49c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (3.8.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.21 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: seaborn in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from seaborn) (3.8.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgLDFrnOy16M",
        "outputId": "adb289f3-2669-47ca-b5c6-611bd90f85c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: tensorflow in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (2.16.1)\n",
            "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: nltk in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (3.8.1)\n",
            "Requirement already satisfied: click in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from nltk) (2024.4.16)\n",
            "Requirement already satisfied: tqdm in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from nltk) (4.66.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mitsa\\desktop\\eestec_2024\\.venv\\lib\\site-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n",
        "!pip install tensorflow\n",
        "!pip install nltk\n",
        "!pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "mWPi5w7s0KNL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "I2KtehCiy5MX"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target         ids                          date      flag  \\\n",
              "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "\n",
              "              user                                               text  \n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....  "
            ]
          },
          "execution_count": 278,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"..\\\\data\\\\raw\\\\1.6M_twitter.csv\", encoding='latin1', header=None, names=['target', 'ids', 'date', 'flag', 'user', 'text'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "target\n",
              "0    800000\n",
              "1    800000\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 279,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['target'] = df['target'].map({0: 0, 4: 1})\n",
        "df['target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "user\n",
              "lost_dog           549\n",
              "webwoke            345\n",
              "tweetpet           310\n",
              "SallytheShizzle    281\n",
              "VioletsCRUK        279\n",
              "mcraddictal        276\n",
              "tsarnick           248\n",
              "what_bugs_u        246\n",
              "Karen230683        238\n",
              "DarkPiano          236\n",
              "SongoftheOss       227\n",
              "Jayme1988          225\n",
              "keza34             219\n",
              "ramdomthoughts     216\n",
              "shanajaca          213\n",
              "wowlew             212\n",
              "nuttychris         211\n",
              "TraceyHewins       211\n",
              "thisgoeshere       207\n",
              "Spidersamm         205\n",
              "StDAY              202\n",
              "felicityfuller     195\n",
              "Dogbook            192\n",
              "_magic8ball        189\n",
              "Djalfy             182\n",
              "Dutchrudder        182\n",
              "torilovesbradie    182\n",
              "twebbstack         180\n",
              "Quimo              180\n",
              "Broooooke_         179\n",
              "enamoredsoul       179\n",
              "MTVnHollyWEST23    178\n",
              "JessMcFlyxxx       178\n",
              "MiDesfileNegro     177\n",
              "KevinEdwardsJr     171\n",
              "linnetwoods        171\n",
              "insearchofnkotb    170\n",
              "Scyranth           166\n",
              "karinb_za          166\n",
              "JBnVFCLover786     163\n",
              "cookiemonster82    160\n",
              "maynaseric         159\n",
              "shellrawlins       159\n",
              "hollyalyxfinch     159\n",
              "lesley007          158\n",
              "mrs_mcsupergirl    158\n",
              "DonniesGirl69      155\n",
              "judez_xo           152\n",
              "paul_steele        152\n",
              "patriciaco         151\n",
              "dtype: int64"
            ]
          },
          "execution_count": 280,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find users with tweets more than 50\n",
        "df.groupby('user').size().sort_values(ascending=False).head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop(['ids', 'date', 'flag', 'user'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1600000 entries, 0 to 1599999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count    Dtype \n",
            "---  ------  --------------    ----- \n",
            " 0   target  1600000 non-null  int64 \n",
            " 1   text    1600000 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 24.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>- Awww, that's a bummer.  You shoulda got Da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>I dived many times for the ball. Managed to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>no, it's not behaving at all. i'm mad. why am...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                               text\n",
              "0       0    - Awww, that's a bummer.  You shoulda got Da...\n",
              "1       0  is upset that he can't update his Facebook by ...\n",
              "2       0   I dived many times for the ball. Managed to s...\n",
              "3       0    my whole body feels itchy and like its on fire \n",
              "4       0   no, it's not behaving at all. i'm mad. why am..."
            ]
          },
          "execution_count": 283,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text'] = df['text'].str.replace(r'@\\w+', '', regex=True)  # Remove @mentions\n",
        "df['text'] = df['text'].str.replace(r'https?://\\S+', '', regex=True)  # Remove URLs\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>- Awww, that's a bummer.  You shoulda got Da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>I dived many times for the ball. Managed to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>no, it's not behaving at all. i'm mad. why am...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                               text\n",
              "0       0    - Awww, that's a bummer.  You shoulda got Da...\n",
              "1       0  is upset that he can't update his Facebook by ...\n",
              "2       0   I dived many times for the ball. Managed to s...\n",
              "3       0    my whole body feels itchy and like its on fire \n",
              "4       0   no, it's not behaving at all. i'm mad. why am..."
            ]
          },
          "execution_count": 284,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text'] = df['text'].str.replace('&quot;', '') # Remove &quot;\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [target, text]\n",
              "Index: []"
            ]
          },
          "execution_count": 285,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['text'].str.contains('&quot;')] # validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [target, text]\n",
              "Index: []"
            ]
          },
          "execution_count": 286,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text'] = df['text'].str.replace('&lt;', ' ')  #remove &lt; (less than)\n",
        "df[df['text'].str.contains('&lt;')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [target, text]\n",
              "Index: []"
            ]
          },
          "execution_count": 287,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text'] = df['text'].str.replace('&gt;', ' ')  #remove &gt; (greater than)\n",
        "df[df['text'].str.contains('&gt;')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [target, text]\n",
              "Index: []"
            ]
          },
          "execution_count": 288,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text'] = df['text'].str.replace('--+', '', regex=True) # Remove multiple dashes\n",
        "df[df['text'].str.contains('--+')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [target, text]\n",
              "Index: []"
            ]
          },
          "execution_count": 289,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text'] = df['text'] = df['text'].str.replace('&amp;', 'and')  #replace &amp; with and\n",
        "df[df['text'].str.contains('&amp;')] # validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0          - Awww, that's a bummer.  You shoulda got Davi...\n",
              "1          is upset that he can't update his Facebook by ...\n",
              "2          I dived many times for the ball. Managed to sa...\n",
              "3             my whole body feels itchy and like its on fire\n",
              "4          no, it's not behaving at all. i'm mad. why am ...\n",
              "                                 ...                        \n",
              "1599995    Just woke up. Having no school is the best fee...\n",
              "1599996    TheWDB.com - Very cool to hear old Walt interv...\n",
              "1599997    Are you ready for your MoJo Makeover? Ask me f...\n",
              "1599998    Happy 38th Birthday to my boo of alll time!!! ...\n",
              "1599999                                happy #charitytuesday\n",
              "Name: text, Length: 1600000, dtype: object"
            ]
          },
          "execution_count": 290,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text'].str.strip()  # Remove leading/trailing whitespaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>- Awww, that's a bummer.  You shoulda got Da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>I dived many times for the ball. Managed to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>no, it's not behaving at all. i'm mad. why am...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                               text\n",
              "0       0    - Awww, that's a bummer.  You shoulda got Da...\n",
              "1       0  is upset that he can't update his Facebook by ...\n",
              "2       0   I dived many times for the ball. Managed to s...\n",
              "3       0    my whole body feels itchy and like its on fire \n",
              "4       0   no, it's not behaving at all. i'm mad. why am..."
            ]
          },
          "execution_count": 291,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1558626 entries, 0 to 1599999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count    Dtype \n",
            "---  ------  --------------    ----- \n",
            " 0   target  1558626 non-null  int64 \n",
            " 1   text    1558626 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 35.7+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data shape: (1246900,) (1246900,)\n",
            "Test data shape: (311726,) (311726,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "x_train, y_train = np.array(train_data['text']), np.array(train_data['target'])\n",
        "x_test, y_test = np.array(test_data['text']), np.array(test_data['target'])\n",
        "\n",
        "#Print the sizes of the train, dev, and test sets\n",
        "print(\"Train data shape:\", x_train.shape , y_train.shape)\n",
        "print(\"Test data shape:\", x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " So they still cant find them?? Thats tragic...  0\n",
            "tia and/or tamera from sister, sister is on a tbn commercial. I love it when I see celebrities praising God. I love it.  1\n"
          ]
        }
      ],
      "source": [
        "print(x_train[0], y_train[0])\n",
        "print(x_test[0], y_test[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training data average document length = 12.857509824364424\n"
          ]
        }
      ],
      "source": [
        "train_doc_length = 0\n",
        "for word in x_train:\n",
        "  tokens = str(word).split()\n",
        "  train_doc_length += len(tokens)\n",
        "\n",
        "print('\\nTraining data average document length =', (train_doc_length / len(x_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "VOCAB_SIZE = 3000000\n",
        "SEQ_MAX_LENGTH = 20\n",
        "vectorizer = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE, \n",
        "                                               output_mode='int', \n",
        "                                               ngrams=1, name='vector_text',\n",
        "                                               output_sequence_length=SEQ_MAX_LENGTH)\n",
        "\n",
        "with tf.device('/CPU:0'):\n",
        "  vectorizer.adapt(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, roc_curve, roc_auc_score, auc\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "from seaborn import heatmap\n",
        "from pandas import DataFrame\n",
        "import IPython.display as ipd\n",
        "\n",
        "\n",
        "def classification_data_nn(estimator, \n",
        "                          x_train, y_train,\n",
        "                          x_test, y_test, \n",
        "                          epochs=1, \n",
        "                          num_layers=1,\n",
        "                          emb_size=64,\n",
        "                          h_size=64,\n",
        "                          batch_size=64,\n",
        "                          splits=5):\n",
        "  \n",
        "  train_accuracies, test_accuracies, train_precisions, test_precisions, train_recall, test_recall, train_f1, test_f1 = [], [], [], [], [], [], [], []\n",
        "  \n",
        "  split_size = int(len(x_train) / splits)\n",
        "  x_splits = np.split(x_train, splits)\n",
        "  y_splits = np.split(y_train, splits)\n",
        "  test_cm = None\n",
        "  \n",
        "  for i in range(0, len(x_splits)):\n",
        "    if i == 0:\n",
        "      curr_x = x_splits[0]\n",
        "      curr_y = y_splits[0]\n",
        "    else:\n",
        "      curr_x = np.concatenate((curr_x, x_splits[i]), axis=0)\n",
        "      curr_y = np.concatenate((curr_y, y_splits[i]), axis=0)\n",
        "    \n",
        "    new_estimator = estimator(num_layers=num_layers, emb_size=emb_size, h_size=h_size)\n",
        "    model = new_estimator.get_model()\n",
        "    est_his = model.fit(curr_x, curr_y, epochs=epochs, batch_size=batch_size)\n",
        "    \n",
        "    train_pred = model.predict(curr_x)\n",
        "    test_pred = model.predict(x_test)\n",
        "    \n",
        "    train_pred = np.round(train_pred)\n",
        "    test_pred = np.round(test_pred)\n",
        "\n",
        "    train_accuracies.append(accuracy_score(curr_y, train_pred))\n",
        "    test_accuracies.append(accuracy_score(y_test, test_pred))\n",
        "    \n",
        "    train_precisions.append(precision_score(curr_y, train_pred))\n",
        "    test_precisions.append(precision_score(y_test, test_pred))\n",
        "    \n",
        "    train_recall.append(recall_score(curr_y, train_pred))\n",
        "    test_recall.append(recall_score(y_test, test_pred))\n",
        "    \n",
        "    train_f1.append(f1_score(curr_y, train_pred))\n",
        "    test_f1.append(f1_score(y_test, test_pred))\n",
        "\n",
        "\n",
        "  return {'estimator': new_estimator.__name__, \n",
        "          'splits': splits,\n",
        "          'split_size': split_size, \n",
        "          'test_predictions': test_pred,\n",
        "          'test_predictions_cont': test_pred,\n",
        "          'train_accuracy': train_accuracies, \n",
        "          'test_accuracy': test_accuracies, \n",
        "          'train_precision': train_precisions, \n",
        "          'test_precision': test_precisions, \n",
        "          'train_recall': train_recall, \n",
        "          'test_recall': test_recall, \n",
        "          'train_f1': train_f1, \n",
        "          'test_f1': test_f1,\n",
        "          }\n",
        "\n",
        "def classification_data(estimator, \n",
        "                          x_train, y_train,\n",
        "                          x_test, y_test,\n",
        "                          splits = 5):\n",
        "  train_accuracies, test_accuracies, train_precisions, test_precisions, train_recall, test_recall, train_f1, test_f1 = [], [], [], [], [], [], [], []\n",
        "  \n",
        "  # Split the training data into n splits\n",
        "  split_size = int(len(x_train) / splits)\n",
        "  x_splits = np.split(x_train, splits)\n",
        "  y_splits = np.split(y_train, splits)\n",
        "  \n",
        "  # Train the model on each split and evaluate on the test set\n",
        "  for i in range(0, len(x_splits)):\n",
        "    if i == 0:\n",
        "      curr_x = x_splits[0]\n",
        "      curr_y = y_splits[0]\n",
        "    else:\n",
        "      curr_x = np.concatenate((curr_x, x_splits[i]), axis=0)\n",
        "      curr_y = np.concatenate((curr_y, y_splits[i]), axis=0)\n",
        "    \n",
        "    # Train the model and get train/test predictions\n",
        "    estimator.fit(curr_x, curr_y)\n",
        "    train_pred = estimator.predict(curr_x)\n",
        "    test_pred = estimator.predict(x_test)\n",
        "    \n",
        "    # Calculate and save the necessary metrics for this train/test split\n",
        "    train_accuracies.append(accuracy_score(curr_y, train_pred))\n",
        "    test_accuracies.append(accuracy_score(y_test, test_pred))\n",
        "    \n",
        "    train_precisions.append(precision_score(curr_y, train_pred))\n",
        "    test_precisions.append(precision_score(y_test, test_pred))\n",
        "    \n",
        "    train_recall.append(recall_score(curr_y, train_pred))\n",
        "    test_recall.append(recall_score(y_test, test_pred))\n",
        "    \n",
        "    train_f1.append(f1_score(curr_y, train_pred))\n",
        "    test_f1.append(f1_score(y_test, test_pred))\n",
        "\n",
        "  \n",
        "  # Results required for all the future plots/tables\n",
        "  return {'estimator': estimator.__class__.__name__, \n",
        "          'split_size': split_size, \n",
        "          'splits': splits,\n",
        "          'test_predictions': test_pred,\n",
        "          'train_accuracy': train_accuracies, \n",
        "          'test_accuracy': test_accuracies, \n",
        "          'train_precision': train_precisions, \n",
        "          'test_precision': test_precisions, \n",
        "          'train_recall': train_recall, \n",
        "          'test_recall': test_recall, \n",
        "          'train_f1': train_f1, \n",
        "          'test_f1': test_f1}\n",
        "  \n",
        "def classification_plots(classification_data, full_scale=False):\n",
        "  split_size = classification_data['split_size']\n",
        "  splits = classification_data['splits']\n",
        "  \n",
        "  figure, axis = plt.subplots(2, 2, figsize=(6, 6), dpi=100, gridspec_kw={'width_ratios': [1, 1], 'height_ratios': [1, 1]})\n",
        "  figure.suptitle(\"Learning Curve for {estimator}\".format(estimator=classification_data['estimator']), fontsize=16)\n",
        "  labels = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
        "  \n",
        "  for i in range(0, 2):\n",
        "    for j in range(0, 2):\n",
        "      axis[i, j].set_title(labels[i * 2 + j])\n",
        "      axis[i, j].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
        "      if full_scale:\n",
        "        axis[i, j].axis(ymin=0, ymax=1.02)\n",
        "      axis[i, j].plot(list(range(split_size, splits*split_size + split_size, split_size)), classification_data['train_' + labels[i * 2 + j].lower().replace(' ', '_')], '-', color=\"#2c8dc9\", label=\"Training\")\n",
        "      axis[i, j].plot(list(range(split_size, splits*split_size + split_size, split_size)), classification_data['test_' + labels[i * 2 + j].lower().replace(' ', '_')], '-', color=\"#FFAD00\", label=\"Testing\")\n",
        "      axis[i, j].grid(alpha = 0.3)  \n",
        "  \n",
        "  handles, labels = axis[1, 1].get_legend_handles_labels()\n",
        "  figure.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.05), ncol=2, fancybox=True, shadow=True)\n",
        "  figure.tight_layout()\n",
        " \n",
        "  return figure\n",
        "\n",
        "\n",
        "def classification_table(classification_data):\n",
        "  split_size = classification_data['split_size']\n",
        "  df = DataFrame(data={'Train Accuracy': np.round(classification_data['train_accuracy'], 2), \n",
        "                         'Test Accuracy': np.round(classification_data['test_accuracy'], 2), \n",
        "                         'Precision Train' : np.round(classification_data['train_precision'], 2), \n",
        "                         'Precision Test' : np.round(classification_data['test_precision'], 2), \n",
        "                         'Recall Train' : np.round(classification_data['train_recall'], 2), \n",
        "                         'Recall Test' : np.round(classification_data['test_recall'], 2), \n",
        "                         'F1 Train' : np.round(classification_data['train_f1'], 2), \n",
        "                         'F1 Test' : np.round(classification_data['test_f1'], 2)}, \n",
        "                   index=list(range(split_size, len(x_train) + split_size, split_size)))\n",
        "  return df\n",
        "\n",
        "def classification_plots_compare(classification_data_x, classification_data_y, full_scale=False):\n",
        "  \"\"\"\n",
        "  Plots the learning curves for the train/test accuracies, precisions, recalls\n",
        "  and F1 scores for each split in one figure for both classifiers.\n",
        "  \n",
        "  Arguments:\n",
        "    classification_data_x: The dictionary containing the train/test data for the first classifier.\n",
        "    classification_data_y: The dictionary containing the train/test data for the second classifier.\n",
        "    full_scale: Whether or not to plot the full scale of the y-axis.\n",
        "  Returns: \n",
        "    A figure containing the learning curves for the train/test accuracies, precisions, recalls and F1 scores \n",
        "    for both classifiers.\n",
        "  \"\"\"\n",
        "  \n",
        "  split_size = classification_data_x['split_size']\n",
        "  splits = classification_data_x['splits']\n",
        "  \n",
        "  figure, axis = plt.subplots(2, 2, figsize=(6, 6), dpi=100, gridspec_kw={'width_ratios': [1, 1], 'height_ratios': [1, 1]})\n",
        "  figure.suptitle(\"Learning Curve Comparison for {estimator} against {estimator_2} \".format(estimator=classification_data_x['estimator'], estimator_2=classification_data_y['estimator']), fontsize=12)\n",
        "  labels = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
        "  \n",
        "  for i in range(0, 2):\n",
        "    for j in range(0, 2):\n",
        "      axis[i, j].set_title(labels[i * 2 + j])\n",
        "      axis[i, j].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
        "      if full_scale:\n",
        "        axis[i, j].axis(ymin=0, ymax=1.02)\n",
        "      axis[i, j].plot(list(range(split_size, splits*split_size + split_size, split_size)), classification_data_y['train_' + labels[i * 2 + j].lower().replace(' ', '_')], '-', color=\"#AD49C2\", label=\"Training {estimator}\".format(estimator=classification_data_y['estimator']))\n",
        "      axis[i, j].plot(list(range(split_size, splits*split_size + split_size, split_size)), classification_data_y['test_' + labels[i * 2 + j].lower().replace(' ', '_')], '-', color=\"#7CC249\", label=\"Testing {estimator}\".format(estimator=classification_data_y['estimator']))\n",
        "      axis[i, j].plot(list(range(split_size, splits*split_size + split_size, split_size)), classification_data_x['train_' + labels[i * 2 + j].lower().replace(' ', '_')], '-', color=\"#2c8dc9\", label=\"Training {estimator}\".format(estimator=classification_data_x['estimator']))\n",
        "      axis[i, j].plot(list(range(split_size, splits*split_size + split_size, split_size)), classification_data_x['test_' + labels[i * 2 + j].lower().replace(' ', '_')], '-', color=\"#FFAD00\", label=\"Testing {estimator}\".format(estimator=classification_data_x['estimator']))\n",
        "      axis[i, j].grid(alpha = 0.3) \n",
        "    \n",
        "  handles, labels = axis[1, 1].get_legend_handles_labels()\n",
        "  figure.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.1), ncol=2, fancybox=True, shadow=True)\n",
        "  figure.tight_layout()\n",
        "  return figure\n",
        "\n",
        "\n",
        "def roc_curve_plot(y_pred_cont, name):\n",
        "  fpr, tpr, _ = roc_curve(y_test, y_pred_cont)\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "\n",
        "  figure, axis = plt.subplots(1, 1, figsize=(6, 6), dpi=100)\n",
        "  axis.plot(fpr, tpr, color='#2c8dc9', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "  axis.plot([0, 1], [0, 1], color='#FFAD00', lw=2, linestyle='--', label='No Skill')\n",
        "  axis.set_xlim([0.0, 1.0])\n",
        "  axis.set_ylim([0.0, 1.05])\n",
        "  axis.set_xlabel('False Positive Rate')\n",
        "  axis.set_ylabel('True Positive Rate')\n",
        "  axis.set_title('Receiver operating characteristic for {estimator}'.format(estimator=name))\n",
        "  axis.legend(loc=\"lower right\")\n",
        "  axis.grid(alpha = 0.3)\n",
        "\n",
        "  return figure\n",
        "\n",
        "def loss_plot(loss, val_loss, name):\n",
        "  figure, axis = plt.subplots(1, 1, figsize=(6, 6), dpi=100)\n",
        "  epochs = range(1, len(loss)+1)\n",
        "  axis.plot(epochs, loss, color='#2c8dc9', lw=2, label='Loss')\n",
        "  axis.plot(epochs, val_loss, color='#FFAD00', lw=2, label='Validation Loss')\n",
        "  axis.set_xlabel('Epoch')\n",
        "  axis.set_ylabel('Loss')\n",
        "  axis.set_title('Loss over Epochs for {estimator}'.format(estimator=name))\n",
        "  axis.legend(loc=\"upper right\")\n",
        "  axis.grid(alpha = 0.3)\n",
        "\n",
        "  return figure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"biGRU_RNN\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"biGRU_RNN\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ txt_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ vector_text         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ txt_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ word_embeddings     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">23,700,736</span> │ vector_text[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ vector_text[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,920</span> │ word_embeddings[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lr (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ txt_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ vector_text         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ txt_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ word_embeddings     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │ \u001b[38;5;34m23,700,736\u001b[0m │ vector_text[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ vector_text[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m49,920\u001b[0m │ word_embeddings[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_5[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lr (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,750,785</span> (90.60 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,750,785\u001b[0m (90.60 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,750,785</span> (90.60 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,750,785\u001b[0m (90.60 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "class bigru_rnn():\n",
        "    \n",
        "    def __init__(self, num_layers=1, emb_size=64, h_size=64):\n",
        "        self.num_layers = num_layers\n",
        "        self.emb_size = emb_size\n",
        "        self.h_size = h_size\n",
        "        \n",
        "        inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name='txt_input')\n",
        "        x = vectorizer(inputs)\n",
        "        x = tf.keras.layers.Embedding(input_dim=len(vectorizer.get_vocabulary()),\n",
        "                                        output_dim=self.emb_size, name='word_embeddings',\n",
        "                                        mask_zero=True)(x)\n",
        "        \n",
        "        for n in range(self.num_layers):\n",
        "            if n != self.num_layers - 1:\n",
        "                x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=self.h_size, \n",
        "                                    name=f'bigru_cell_{n}', \n",
        "                                    return_sequences=True,\n",
        "                                    dropout=0.2))(x)\n",
        "            else:\n",
        "                x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=self.h_size, \n",
        "                                                name=f'bigru_cell_{n}',\n",
        "                                                dropout=0.2))(x)\n",
        "        x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
        "         \n",
        "        o = tf.keras.layers.Dense(units=1, activation='sigmoid', name='lr')(x)\n",
        "        \n",
        "        self.model = tf.keras.models.Model(inputs=inputs, outputs=o, name='biGRU_RNN')\n",
        "        self.model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.BinaryCrossentropy())\n",
        "\n",
        "    def __name__(self):\n",
        "        return 'biGRU RNN'\n",
        "    \n",
        "    def fit(self, x_train, y_train, epochs=1, batch_size=64, validation_split=0):\n",
        "        self.model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n",
        "    \n",
        "    def get_model(self):\n",
        "        return self.model\n",
        "      \n",
        "loss_rnn = bigru_rnn(num_layers=1, emb_size=64, h_size=64)\n",
        "model = loss_rnn.get_model()\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rnn_hist = model.fit(x_train, y_train, epochs=6, batch_size=128, validation_split=0.2)\n",
        "rnn_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rnn_ls_plt = loss_plot(rnn_hist.history['loss'], rnn_hist.history['val_loss'], model.name)\n",
        "rnn_auc_plt = roc_curve_plot(rnn_pred, model.name)\n",
        "\n",
        "# from tensorflow.keras.utils import plot_model\n",
        "# from IPython.display import Image \n",
        "# plot_model(model, to_file='model.png', show_shapes=True)\n",
        "# Image('model.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
