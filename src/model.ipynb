{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 300000   # Number of words in the vocabulary\n",
    "n = 300     # N most frequent words to skip\n",
    "k = 30000      # K least frequent words to skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, temp_data = train_test_split(df['text'], test_size=0.2, random_state=42)\n",
    "\n",
    "#Split the temp data into dev and test sets\n",
    "dev_data, test_data = train_test_split(temp_data, test_size=0.7, random_state=42)\n",
    "\n",
    "#Print the sizes of the train, dev, and test sets\n",
    "print(\"Train data size:\", len(train_data))\n",
    "print(\"Dev data size:\", len(dev_data))\n",
    "print(\"Test data size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=m-k, skip_top=n)\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "index2word = dict((i + 3, word) for (word, i) in word_index.items())\n",
    "index2word[0] = '[pad]'\n",
    "index2word[1] = '[bos]'\n",
    "index2word[2] = '[oov]'\n",
    "\n",
    "x_train = np.array([' '.join([index2word[idx] for idx in text]) for text in x_train])\n",
    "x_test = np.array([' '.join([index2word[idx] for idx in text]) for text in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_length = 0\n",
    "for doc in x_train:\n",
    "  tokens = str(doc).split()\n",
    "  train_doc_length += len(tokens)\n",
    "\n",
    "print('\\nTraining data average document length =', (train_doc_length / len(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 100000\n",
    "SEQ_MAX_LENGTH = 240\n",
    "vectorizer = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE, \n",
    "                                               output_mode='int', \n",
    "                                               ngrams=1, name='vector_text',\n",
    "                                               output_sequence_length=SEQ_MAX_LENGTH)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "  vectorizer.adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, roc_curve, roc_auc_score, auc\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from seaborn import heatmap\n",
    "from pandas import DataFrame\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "def classification_data_nn(estimator, \n",
    "                          x_train, y_train,\n",
    "                          x_test, y_test, \n",
    "                          epochs=1, \n",
    "                          num_layers=1,\n",
    "                          emb_size=64,\n",
    "                          h_size=64,\n",
    "                          batch_size=64,\n",
    "                          splits=5):\n",
    "  \n",
    "  train_accuracies, test_accuracies, train_precisions, test_precisions, train_recall, test_recall, train_f1, test_f1 = [], [], [], [], [], [], [], []\n",
    "  \n",
    "  split_size = int(len(x_train) / splits)\n",
    "  x_splits = np.split(x_train, splits)\n",
    "  y_splits = np.split(y_train, splits)\n",
    "  test_cm = None\n",
    "  \n",
    "  for i in range(0, len(x_splits)):\n",
    "    if i == 0:\n",
    "      curr_x = x_splits[0]\n",
    "      curr_y = y_splits[0]\n",
    "    else:\n",
    "      curr_x = np.concatenate((curr_x, x_splits[i]), axis=0)\n",
    "      curr_y = np.concatenate((curr_y, y_splits[i]), axis=0)\n",
    "    \n",
    "    new_estimator = estimator(num_layers=num_layers, emb_size=emb_size, h_size=h_size)\n",
    "    model = new_estimator.get_model()\n",
    "    est_his = model.fit(curr_x, curr_y, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    train_pred = model.predict(curr_x)\n",
    "    test_pred = model.predict(x_test)\n",
    "    \n",
    "    train_pred = np.round(train_pred)\n",
    "    test_pred = np.round(test_pred)\n",
    "\n",
    "    train_accuracies.append(accuracy_score(curr_y, train_pred))\n",
    "    test_accuracies.append(accuracy_score(y_test, test_pred))\n",
    "    \n",
    "    train_precisions.append(precision_score(curr_y, train_pred))\n",
    "    test_precisions.append(precision_score(y_test, test_pred))\n",
    "    \n",
    "    train_recall.append(recall_score(curr_y, train_pred))\n",
    "    test_recall.append(recall_score(y_test, test_pred))\n",
    "    \n",
    "    train_f1.append(f1_score(curr_y, train_pred))\n",
    "    test_f1.append(f1_score(y_test, test_pred))\n",
    "\n",
    "\n",
    "  return {'estimator': new_estimator.__name__, \n",
    "          'splits': splits,\n",
    "          'split_size': split_size, \n",
    "          'test_predictions': test_pred,\n",
    "          'test_predictions_cont': test_pred,\n",
    "          'train_accuracy': train_accuracies, \n",
    "          'test_accuracy': test_accuracies, \n",
    "          'train_precision': train_precisions, \n",
    "          'test_precision': test_precisions, \n",
    "          'train_recall': train_recall, \n",
    "          'test_recall': test_recall, \n",
    "          'train_f1': train_f1, \n",
    "          'test_f1': test_f1,\n",
    "          }\n",
    "\n",
    "def classification_data(estimator, \n",
    "                          x_train, y_train,\n",
    "                          x_test, y_test,\n",
    "                          splits = 5):\n",
    "  train_accuracies, test_accuracies, train_precisions, test_precisions, train_recall, test_recall, train_f1, test_f1 = [], [], [], [], [], [], [], []\n",
    "  \n",
    "  # Split the training data into n splits\n",
    "  split_size = int(len(x_train) / splits)\n",
    "  x_splits = np.split(x_train, splits)\n",
    "  y_splits = np.split(y_train, splits)\n",
    "  \n",
    "  # Train the model on each split and evaluate on the test set\n",
    "  for i in range(0, len(x_splits)):\n",
    "    if i == 0:\n",
    "      curr_x = x_splits[0]\n",
    "      curr_y = y_splits[0]\n",
    "    else:\n",
    "      curr_x = np.concatenate((curr_x, x_splits[i]), axis=0)\n",
    "      curr_y = np.concatenate((curr_y, y_splits[i]), axis=0)\n",
    "    \n",
    "    # Train the model and get train/test predictions\n",
    "    estimator.fit(curr_x, curr_y)\n",
    "    train_pred = estimator.predict(curr_x)\n",
    "    test_pred = estimator.predict(x_test)\n",
    "    \n",
    "    # Calculate and save the necessary metrics for this train/test split\n",
    "    train_accuracies.append(accuracy_score(curr_y, train_pred))\n",
    "    test_accuracies.append(accuracy_score(y_test, test_pred))\n",
    "    \n",
    "    train_precisions.append(precision_score(curr_y, train_pred))\n",
    "    test_precisions.append(precision_score(y_test, test_pred))\n",
    "    \n",
    "    train_recall.append(recall_score(curr_y, train_pred))\n",
    "    test_recall.append(recall_score(y_test, test_pred))\n",
    "    \n",
    "    train_f1.append(f1_score(curr_y, train_pred))\n",
    "    test_f1.append(f1_score(y_test, test_pred))\n",
    "\n",
    "  \n",
    "  # Results required for all the future plots/tables\n",
    "  return {'estimator': estimator.__class__.__name__, \n",
    "          'split_size': split_size, \n",
    "          'splits': splits,\n",
    "          'test_predictions': test_pred,\n",
    "          'train_accuracy': train_accuracies, \n",
    "          'test_accuracy': test_accuracies, \n",
    "          'train_precision': train_precisions, \n",
    "          'test_precision': test_precisions, \n",
    "          'train_recall': train_recall, \n",
    "          'test_recall': test_recall, \n",
    "          'train_f1': train_f1, \n",
    "          'test_f1': test_f1}\n",
    "  \n",
    "def classification_plots(classification_data, full_scale=False):\n",
    "  split_size = classification_data['split_size']\n",
    "  splits = classification_data['splits']\n",
    "  \n",
    "  figure, axis = plt.subplots(2, 2, figsize=(6, 6), dpi=100, gridspec_kw={'width_ratios': [1, 1], 'height_ratios': [1, 1]})\n",
    "  figure.suptitle(\"Learning Curve for {estimator}\".format(estimator=classification_data['estimator']), fontsize=16)\n",
    "  labels = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "  \n",
    "  for i in range(0, 2):\n",
    "    for j in range(0, 2):\n",
    "      axis[i, j].set_title(labels[i * 2 + j])\n",
    "      axis[i, j].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "      if full_scale:\n",
    "        axis[i, j].axis(ymin=0, ymax=1.02)\n",
    "      axis[i, j].plot(list(range(split_size, splits*split_size + split_size, split_size)), classification_data['train_' + labels[i * 2 + j].lower().replace(' ', '_')], '-', color=\"#2c8dc9\", label=\"Training\")\n",
    "      axis[i, j].plot(list(range(split_size, splits*split_size + split_size, split_size)), classification_data['test_' + labels[i * 2 + j].lower().replace(' ', '_')], '-', color=\"#FFAD00\", label=\"Testing\")\n",
    "      axis[i, j].grid(alpha = 0.3)  \n",
    "  \n",
    "  handles, labels = axis[1, 1].get_legend_handles_labels()\n",
    "  figure.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.05), ncol=2, fancybox=True, shadow=True)\n",
    "  figure.tight_layout()\n",
    " \n",
    "  return figure\n",
    "\n",
    "\n",
    "def classification_table(classification_data):\n",
    "  split_size = classification_data['split_size']\n",
    "  df = DataFrame(data={'Train Accuracy': np.round(classification_data['train_accuracy'], 2), \n",
    "                         'Test Accuracy': np.round(classification_data['test_accuracy'], 2), \n",
    "                         'Precision Train' : np.round(classification_data['train_precision'], 2), \n",
    "                         'Precision Test' : np.round(classification_data['test_precision'], 2), \n",
    "                         'Recall Train' : np.round(classification_data['train_recall'], 2), \n",
    "                         'Recall Test' : np.round(classification_data['test_recall'], 2), \n",
    "                         'F1 Train' : np.round(classification_data['train_f1'], 2), \n",
    "                         'F1 Test' : np.round(classification_data['test_f1'], 2)}, \n",
    "                   index=list(range(split_size, len(x_train) + split_size, split_size)))\n",
    "  return df\n",
    "\n",
    "def classification_plots_compare(classification_data_x, classification_data_y, full_scale=False):\n",
    "  \"\"\"\n",
    "  Plots the learning curves for the train/test accuracies, precisions, recalls\n",
    "  and F1 scores for each split in one figure for both classifiers.\n",
    "  \n",
    "  Arguments:\n",
    "    classification_data_x: The dictionary containing the train/test data for the first classifier.\n",
    "    classification_data_y: The dictionary containing the train/test data for the second classifier.\n",
    "    full_scale: Whether or not to plot the full scale of the y-axis.\n",
    "  Returns: \n",
    "    A figure containing the learning curves for the train/test accuracies, precisions, recalls and F1 scores \n",
    "    for both classifiers.\n",
    "  \"\"\"\n",
    "  \n",
    "  split_size = classification_data_x['split_size']\n",
    "  splits = classification_data_x['splits']\n",
    "  \n",
    "  figure, axis = plt.subplots(2, 2, figsize=(6, 6), dpi=100, gridspec_kw={'width_ratios': [1, 1], 'height_ratios': [1, 1]})\n",
    "  figure.suptitle(\"Learning Curve Comparison for {estimator} against {estimator_2} \".format(estimator=classification_data_x['estimator'], estimator_2=classification_data_y['estimator']), fontsize=12)\n",
    "  labels = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "  \n",
    "  for i in range(0, 2):\n",
    "    for j in range(0, 2):\n",
    "      axis[i, j].set_title(labels[i * 2 + j])\n",
    "      axis[i, j].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "      if full_scale:\n",
    "        axis[i, j].axis(ymin=0, ymax=1.02)\n",
    "      axis[i, j].plot(list(range(split_size, splits*split_size + split_size, split_size)), classification_data_y['train_' + labels[i * 2 + j].lower().replace(' ', '_')], '-', color=\"#AD49C2\", label=\"Training {estimator}\".format(estimator=classification_data_y['estimator']))\n",
    "      axis[i, j].plot(list(range(split_size, splits*split_size + split_size, split_size)), classification_data_y['test_' + labels[i * 2 + j].lower().replace(' ', '_')], '-', color=\"#7CC249\", label=\"Testing {estimator}\".format(estimator=classification_data_y['estimator']))\n",
    "      axis[i, j].plot(list(range(split_size, splits*split_size + split_size, split_size)), classification_data_x['train_' + labels[i * 2 + j].lower().replace(' ', '_')], '-', color=\"#2c8dc9\", label=\"Training {estimator}\".format(estimator=classification_data_x['estimator']))\n",
    "      axis[i, j].plot(list(range(split_size, splits*split_size + split_size, split_size)), classification_data_x['test_' + labels[i * 2 + j].lower().replace(' ', '_')], '-', color=\"#FFAD00\", label=\"Testing {estimator}\".format(estimator=classification_data_x['estimator']))\n",
    "      axis[i, j].grid(alpha = 0.3) \n",
    "    \n",
    "  handles, labels = axis[1, 1].get_legend_handles_labels()\n",
    "  figure.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.1), ncol=2, fancybox=True, shadow=True)\n",
    "  figure.tight_layout()\n",
    "  return figure\n",
    "\n",
    "\n",
    "def roc_curve_plot(y_pred_cont, name):\n",
    "  fpr, tpr, _ = roc_curve(y_test, y_pred_cont)\n",
    "  roc_auc = auc(fpr, tpr)\n",
    "\n",
    "  figure, axis = plt.subplots(1, 1, figsize=(6, 6), dpi=100)\n",
    "  axis.plot(fpr, tpr, color='#2c8dc9', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "  axis.plot([0, 1], [0, 1], color='#FFAD00', lw=2, linestyle='--', label='No Skill')\n",
    "  axis.set_xlim([0.0, 1.0])\n",
    "  axis.set_ylim([0.0, 1.05])\n",
    "  axis.set_xlabel('False Positive Rate')\n",
    "  axis.set_ylabel('True Positive Rate')\n",
    "  axis.set_title('Receiver operating characteristic for {estimator}'.format(estimator=name))\n",
    "  axis.legend(loc=\"lower right\")\n",
    "  axis.grid(alpha = 0.3)\n",
    "\n",
    "  return figure\n",
    "\n",
    "def loss_plot(loss, val_loss, name):\n",
    "  figure, axis = plt.subplots(1, 1, figsize=(6, 6), dpi=100)\n",
    "  epochs = range(1, len(loss)+1)\n",
    "  axis.plot(epochs, loss, color='#2c8dc9', lw=2, label='Loss')\n",
    "  axis.plot(epochs, val_loss, color='#FFAD00', lw=2, label='Validation Loss')\n",
    "  axis.set_xlabel('Epoch')\n",
    "  axis.set_ylabel('Loss')\n",
    "  axis.set_title('Loss over Epochs for {estimator}'.format(estimator=name))\n",
    "  axis.legend(loc=\"upper right\")\n",
    "  axis.grid(alpha = 0.3)\n",
    "\n",
    "  return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bigru_rnn():\n",
    "    \n",
    "    def __init__(self, num_layers=1, emb_size=64, h_size=64):\n",
    "        self.num_layers = num_layers\n",
    "        self.emb_size = emb_size\n",
    "        self.h_size = h_size\n",
    "        \n",
    "        inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name='txt_input')\n",
    "        x = vectorizer(inputs)\n",
    "        x = tf.keras.layers.Embedding(input_dim=len(vectorizer.get_vocabulary()),\n",
    "                                        output_dim=self.emb_size, name='word_embeddings',\n",
    "                                        mask_zero=True)(x)\n",
    "        \n",
    "        for n in range(self.num_layers):\n",
    "            if n != self.num_layers - 1:\n",
    "                x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=self.h_size, \n",
    "                                    name=f'bigru_cell_{n}', \n",
    "                                    return_sequences=True,\n",
    "                                    dropout=0.2))(x)\n",
    "            else:\n",
    "                x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=self.h_size, \n",
    "                                                name=f'bigru_cell_{n}',\n",
    "                                                dropout=0.2))(x)\n",
    "        x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "         \n",
    "        o = tf.keras.layers.Dense(units=1, activation='sigmoid', name='lr')(x)\n",
    "        \n",
    "        self.model = tf.keras.models.Model(inputs=inputs, outputs=o, name='biGRU_RNN')\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.BinaryCrossentropy())\n",
    "\n",
    "    def __name__(self):\n",
    "        return 'biGRU RNN'\n",
    "    \n",
    "    def fit(self, x_train, y_train, epochs=1, batch_size=64, validation_split=0):\n",
    "        self.model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "      \n",
    "loss_rnn = bigru_rnn(num_layers=1, emb_size=64, h_size=64)\n",
    "model = loss_rnn.get_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster weight Layer\n",
    "class CustomLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        \n",
    "    def call(self, input_1, user_id, training=False):\n",
    "        # Should multiply the input of the previous layer with a coefficient based\n",
    "        # on the cluster that the user that made this tweet belongs to.\n",
    "        # input_1 is the input of the previous layer.\n",
    "        # user_id is the id of the user that made the tweet.\n",
    "        # The cluster is determined by the user_id.\n",
    "        # The coefficient is the weight of the cluster.\n",
    "        \"\"\"\n",
    "        weight = cluster.get(user_id)\n",
    "        \"\"\"\n",
    "        x = input_1*weight\n",
    "\n",
    "        \n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
